{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72599e5-da97-4a8d-ba5e-0e170f021a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "def extract_all_proteins(tar_file, output_dir):\n",
    "    \"\"\"\n",
    "    Extract all .pdb.gz files from a tar file and decompress them.\n",
    "\n",
    "    Args:\n",
    "        tar_file (str): Path to the tar file containing all the proteins.\n",
    "        output_dir (str): Directory to save the extracted protein files.\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Open the tar file\n",
    "    try:\n",
    "        with tarfile.open(tar_file, 'r') as tar_ref:\n",
    "            # Extract all .pdb.gz files\n",
    "            for member in tar_ref.getmembers():\n",
    "                if member.name.endswith('.pdb.gz'):\n",
    "                    try:\n",
    "                        # Extract and decompress .pdb.gz files\n",
    "                        with tar_ref.extractfile(member) as f_in:\n",
    "                            with gzip.GzipFile(fileobj=f_in) as gz_in:\n",
    "                                pdb_filename = os.path.join(output_dir, member.name.replace('.gz', ''))\n",
    "                                with open(pdb_filename, 'wb') as f_out:\n",
    "                                    f_out.write(gz_in.read())\n",
    "                                    print(f\"Extracted and saved {pdb_filename}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {member.name}: {e}\")\n",
    "                else:\n",
    "                    # Ignore other file types\n",
    "                    print(f\"Ignored {member.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening tar file {tar_file}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "tar_file = 'C:/Users/users/Downloads/UP000005640_9606_HUMAN_v4.tar'  # Update with your actual tar file\n",
    "output_dir = 'C:/Users/users/Downloads/HUMAN_extracted_proteins'  # Output directory to extract proteins into\n",
    "extract_all_proteins(tar_file, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3eb7dc-48bc-4341-9f61-ed73093431ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estrazione struttura secondaria da proteoma senza resname \n",
    "import os\n",
    "import pymol\n",
    "from pymol import cmd\n",
    "\n",
    "def extract_and_process_pdb_files(input_directory, output_directory, batch_size):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Initialize PyMOL in non-GUI mode\n",
    "    pymol.finish_launching(['pymol', '-qc'])  # -q for quiet mode, -c for no GUI\n",
    "\n",
    "    # Get a list of all PDB files in the directory\n",
    "    pdb_files = [os.path.join(input_directory, f) for f in os.listdir(input_directory) if f.endswith('.pdb')]\n",
    "\n",
    "    def process_batch(pdb_files, batch_index):\n",
    "        # Clear PyMOL session\n",
    "        cmd.reinitialize()\n",
    "\n",
    "        # Load and process each PDB file\n",
    "        for pdb_file in pdb_files:\n",
    "            cmd.load(pdb_file)\n",
    "\n",
    "        # Dictionaries to store secondary structure and pLDDT scores\n",
    "        secondary_structure = {}\n",
    "        pLDDT_scores = {}\n",
    "\n",
    "        # Collect secondary structure\n",
    "        def collect_secondary_structure(model, resi, ss):\n",
    "            secondary_structure[(model, resi)] = ss\n",
    "\n",
    "        # Collect pLDDT scores\n",
    "        def collect_plddt_scores(model, resi, b):\n",
    "            pLDDT_scores[(model, resi)] = b\n",
    "\n",
    "        # Define a PyMOL expression to collect data\n",
    "        cmd.iterate(\"n. CA\", \"collect_secondary_structure(model, resi, ss)\", space={\"collect_secondary_structure\": collect_secondary_structure})\n",
    "        cmd.iterate(\"n. CA\", \"collect_plddt_scores(model, resi, b)\", space={\"collect_plddt_scores\": collect_plddt_scores})\n",
    "\n",
    "        # Group residues by protein and sort them by ID\n",
    "        residues_by_protein = {}\n",
    "        for (model, resi) in secondary_structure.keys():\n",
    "            if model not in residues_by_protein:\n",
    "                residues_by_protein[model] = []\n",
    "            residues_by_protein[model].append((resi, secondary_structure[(model, resi)], pLDDT_scores.get((model, resi), \"\")))\n",
    "\n",
    "        for model in residues_by_protein:\n",
    "            residues_by_protein[model].sort(key=lambda x: int(x[0]))  # Sort by residue ID\n",
    "\n",
    "        # Write secondary structure information and pLDDT scores into a text file\n",
    "        output_file_path = os.path.join(output_directory, f\"output_batch_{batch_index}.txt\")\n",
    "        with open(output_file_path, 'w') as f:\n",
    "            f.write(\"PDB_ID\\tResidue_ID\\tSecondary_Structure\\tpLDDT_Score\\n\")\n",
    "            for model in sorted(residues_by_protein.keys()):\n",
    "                for (resi, ss, pLDDT) in residues_by_protein[model]:\n",
    "                    pdb_id = \"{}_{}\".format(model, resi)  # Concatenate model name and residue ID\n",
    "                    f.write(\"{}\\t{}\\t{}\\t{:.2f}\\n\".format(pdb_id, resi, ss, float(pLDDT)))\n",
    "\n",
    "        print(f\"Information saved to {output_file_path}\")\n",
    "\n",
    "    # Process the PDB files in batches\n",
    "    for i in range(0, len(pdb_files), batch_size):\n",
    "        batch_files = pdb_files[i:i + batch_size]\n",
    "        process_batch(batch_files, i // batch_size + 1)\n",
    "\n",
    "    # Quit PyMOL\n",
    "    pymol.cmd.quit()\n",
    "\n",
    "# Example usage\n",
    "input_directory = 'C:/Users/users/Downloads/HUMAN_extracted_proteins'   # Update with your actual input directory\n",
    "output_directory = 'C:/Users/users/Downloads/HUMAN_extracted_proteins_output'   # Update with your actual output directory\n",
    "batch_size = 1000  # Number of PDB files to process per batch\n",
    "\n",
    "extract_and_process_pdb_files(input_directory, output_directory, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac562408-77a1-4b98-b8a7-b687bd99f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency analysis script for residue relationships from multiple .txt files\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = 'C:/Users/users/Desktop/HUMAN_extracted_proteins_output/'\n",
    "output_folder = 'C:/Users/users/Desktop/AA_rel_HUMAN/'\n",
    "\n",
    "# Make sure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List all .txt files in the input folder\n",
    "txt_files = [f for f in os.listdir(input_folder) if f.endswith('.txt')]\n",
    "\n",
    "# List of the 20 standard amino acids\n",
    "amino_acids = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE', \n",
    "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL']\n",
    "\n",
    "# Function to calculate residue pair distances for entire protein\n",
    "def calculate_relationship_whole(df, residue_name, window_size=20):\n",
    "    relationships = {f'1-{i}': 0 for i in range(2, window_size+1)}\n",
    "    for protein_id, protein_df in df.groupby('PDB_ID'):\n",
    "        residue_positions = protein_df[protein_df['Residue_Name'] == residue_name]['Residue_ID'].tolist()\n",
    "        for i, pos1 in enumerate(residue_positions):\n",
    "            for pos2 in residue_positions[i+1:]:\n",
    "                dist = abs(pos2 - pos1) + 1\n",
    "                if 2 <= dist <= window_size:\n",
    "                    relationships[f'1-{dist}'] += 1\n",
    "    return relationships\n",
    "\n",
    "# Function to extract continuous segments of specific secondary structure\n",
    "def find_continuous_segments(df, secondary_structure):\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['Secondary_Structure'] == secondary_structure:\n",
    "            current_segment.append(row)\n",
    "        else:\n",
    "            if current_segment:\n",
    "                segments.append(current_segment)\n",
    "            current_segment = []\n",
    "    if current_segment:\n",
    "        segments.append(current_segment)\n",
    "    return segments\n",
    "\n",
    "# Function to calculate residue pair distances within continuous structural motifs\n",
    "def calculate_relationship_continuous_segments(segments, residue_name, window_size=20):\n",
    "    relationships = {f'1-{i}': 0 for i in range(2, window_size+1)}\n",
    "    for segment in segments:\n",
    "        residue_positions = [row['Residue_ID'] for row in segment if row['Residue_Name'] == residue_name]\n",
    "        for i, pos1 in enumerate(residue_positions):\n",
    "            for pos2 in residue_positions[i+1:]:\n",
    "                dist = abs(pos2 - pos1) + 1\n",
    "                if 2 <= dist <= window_size:\n",
    "                    relationships[f'1-{dist}'] += 1\n",
    "    return relationships\n",
    "\n",
    "# Analyze all .txt files in the folder\n",
    "for idx, file_name in enumerate(txt_files, start=1):\n",
    "    print(f'[{idx}/{len(txt_files)}] Processing file: {file_name}')\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "    df = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "    # Extract base protein ID and convert Residue_ID to numeric\n",
    "    df['PDB_ID'] = df['PDB_ID'].str.split('_').str[0]\n",
    "    df['Residue_ID'] = pd.to_numeric(df['Residue_ID'], errors='coerce')\n",
    "\n",
    "    output_file = os.path.join(output_folder, f'Amino_Acid_Relationships_output_{idx}_HUMAN.xlsx')\n",
    "\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        for aa in amino_acids:\n",
    "            print(f'  -> Analyzing amino acid: {aa}')\n",
    "\n",
    "            # Whole protein distance calculation\n",
    "            relationships_whole = calculate_relationship_whole(df, aa)\n",
    "\n",
    "            # Distance calculation within motifs H, S, L\n",
    "            motif_relationships = {}\n",
    "            for motif_type in ['H', 'S', 'L']:\n",
    "                segments = find_continuous_segments(df, motif_type)\n",
    "                motif_relationships[motif_type] = calculate_relationship_continuous_segments(segments, aa)\n",
    "\n",
    "            # Build dataframe with all results\n",
    "            relationship_df = pd.DataFrame({\n",
    "                'Amino Acid Relationship': [f'1-{i}' for i in range(2, 21)],\n",
    "                'Whole_Protein': [relationships_whole.get(f'1-{i}', 0) for i in range(2, 21)]\n",
    "            })\n",
    "\n",
    "            for motif_type, relationships in motif_relationships.items():\n",
    "                motif_values = [relationships.get(f'1-{i}', 0) for i in range(2, 21)]\n",
    "                relationship_df[f'Continuous_{motif_type}'] = motif_values\n",
    "\n",
    "            # Save sheet named by amino acid\n",
    "            relationship_df.to_excel(writer, sheet_name=aa, index=False)\n",
    "\n",
    "print('Analysis completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11914fd-fd34-416e-bc84-4273556bf213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
